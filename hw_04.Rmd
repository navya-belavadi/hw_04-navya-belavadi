---
title: "Homework 04: Statistical inference"
subtitle: "Due: Friday, March 26 11:59pm ET"
author: "Navya Belavadi"
date: "03-21-2021"
output:
  pdf_document: default
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, 
                      warning = FALSE, comment = "#>", highlight = TRUE)
set.seed(37073)
```

# Packages

```{r packages}
library(tidyverse)
library(infer)
```

# Data

```{r load_data}
gifted <- read_csv("https://www.openintro.org/data/csv/gifted.csv")
```

# Exercises

## Exercise 1
The sample size Gallup took in the 2016-2017 nationwide study was 337,690.

## Exercise 2
The quantity 11.5% represents the percent of the national population that was 
told by a doctor or a nurse that they have diabetes during 2016-2017. The 
quantity 10.8% represents the percent of the national population that was told
by a doctor or a nurse that they have diabetes during 2008-2009.

## Exercise 3
The 95% confidence interval for the proportion of adult individuals that have 
diabetes is 11.3% to 11.7%, which can be determined because the margin of 
sampling error was +/- 0.2 and the point estimate was 11.5%. 

## Exercise 4
The 95% confidence interval for the proportion of adults with diabetes in Alaska
is 4.9% to 11.9%, due to the margin of sampling error being +/- 3.5 and the 
point estimate being 8.4%.

## Exercise 5
```{r ex_5}
insurance <- tibble(claims = rep(c("met", "unmet"), times = c(55, 20)))

insurance %>%
  prop_test(response = claims, success = "met", conf_int = FALSE, alternative = 
              "less", z = TRUE, p = 0.9)
```

The point estimate is 55/75 = 0.73333, null hypothesis is p = 0.9, and the 
alternative hypothesis is p < 0.9. Since the p value, 7.499e-7, is less than the
significance level of 0.05, the null hypothesis can be rejected. Therefore, 
there is sufficient evidence that the consumer group is right, and that the true
proportion of claims is less than 90%.

## Exercise 6
```{r ex_6}
sample_p <- insurance %>%
  count(claims) %>%
  mutate(prop = n / sum(n)) %>%
  filter(claims == "met") %>%
  select(prop)

insurance %>%
  specify(response = claims, success = "met") %>%
  hypothesize(null = "point", p = 0.90)%>%
  generate(reps = 10000, type = "simulate") %>%
  calculate(stat = "prop") %>%
  get_p_value(obs_stat = sample_p, direction = "less") %>%
  print(insurance)
```
After using a simulations based approach, the result was a p value of 2e-04, 
which is greater than the previously found value, but still roughly around 0. 
Therefore, you reach the same conclusion as the previous exercise and reject the
null hypothesis. 

## Exercise 7
```{r ex_7}
bootstrap_mean <- gifted %>%
  specify(response = count) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean") %>%
  get_ci(level = 0.98)
bootstrap_mean
```
This output means that one can be 98% confident that the mean number of months 
until gifted children from the specified city can count to 10 is between 29 and 
32.333. 

## Exercise 8

```{r ex_8}
gifted <- gifted %>% 
  pivot_longer(cols      = edutv:cartoons, 
               names_to  = "tv_type", 
               values_to = "tv_hours")
d_hat <- gifted %>%
  specify(tv_hours ~ tv_type) %>%
  calculate(stat = "diff in means", order = c("cartoons", "edutv"))
boot <- gifted %>%
  specify(tv_hours ~ tv_type) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "diff in means", order = c("cartoons", "edutv"))
percentile_ci <- get_ci(boot, level = 0.99)
percentile_ci
```
Based on this confidence interval, gifted children watch more educational TV on
average than cartoons. 


## Exercise 9
A will have the largest interval -- despite A and B being the same size, A has a
confidence interval of 90% rather than 95% which B has. This lower confidence 
interval means the part of the data set that is included will be less narrow 
since the standards are not as high. B will have the second largest interval, 
and C will have the smallest because of the high p value which narrows out half 
of the data set.

## Exercise 10
Some potential consequences from a Type I error could be that a false positive 
would be signaled and the catheter's production would continue even if the 
catheters are not safe to use (the null hypothesis should not have been 
rejected). Potential consequences from a Type II error is that a false negative 
would be signaled and the product of safe catheters would halt (the null 
hypothesis should have been rejected). 

# References

Gallup, I. (2018). Diabetes Rates Rise in 18 States in Past Decade. 
Gallup.com. Retrieved from 
https://news.gallup.com/poll/243911/diabetes-rates-rise-states-past-decade.aspx
